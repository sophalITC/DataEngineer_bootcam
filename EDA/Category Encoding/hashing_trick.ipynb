{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### </b> **Hashing Trick**: </b>\n",
    "<p>  <a style=\"color:#00FFFF\"><b>The hashing trick</b></a> is a dimensionality reduction technique where categories are hashed into a fixed number of bins. This approach can be useful when you have a large number of categories and want to reduce the dimensionality of the encoded variable. However, there is a possibility of hash collisions where different categories may be mapped to the same bin.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Create a dataset with three features: 'dog', 'cat', and 'elephant'\n",
    "data = [{'dog': 1, 'cat': 2}, {'dog': 2, 'run': 5},{'dog': 4,'cat': 2, 'run': 5}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a dataset with three features: ‘dog’, ‘cat’, and ‘elephant’. The dataset contains two samples (dictionaries), where the first sample has values of 1 for ‘dog’, 2 for ‘cat’, and 4 for ‘elephant’, and the second sample has values of 2 for ‘dog’ and 5 for ‘run’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the hashing trick to map each feature to one of 10 bins\n",
    "hasher = FeatureHasher(n_features=4)# Creates a FeatureHasher object with 10 bins. This means that each feature will be mapped to one of 10 integers.\n",
    "hashed_data = hasher.transform(data)# Uses the FeatureHasher object to transform the dataset. This results in a sparse matrix with 10 columns and 2 rows.\n",
    "# The columns represent the 10 bins, and the rows represent the two data points in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the hashing trick to map each feature to one of 10 bins. The FeatureHasher class from scikit-learn is used to perform this operation. The n_features parameter specifies the number of bins to use. The transform() method is used to apply the hashing trick to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.  0.  2.]\n",
      " [-5. -2.  0.  0.]\n",
      " [-5. -4.  0.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Print the hashed data\n",
    "print(hashed_data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prints the hashed data. The toarray() method is used to convert the hashed data into a NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is an example of how to use the hashing trick in scikit-learn to encode categorical variables in a dataset. The FeatureHasher class from the sklearn.feature_extraction module is used to perform the hashing trick.\n",
    "\n",
    "In this example, the data variable is a list of dictionaries where each dictionary represents a row in the dataset. The keys in each dictionary represent the categorical variables and the values represent the categories.\n",
    "\n",
    "The FeatureHasher object is created with n_features=2, which means that it will generate two features for each row in the dataset. The input_type parameter is set to ‘dict’ to indicate that the input data is a list of dictionaries.\n",
    "\n",
    "The transform method of the FeatureHasher object is then called with the data variable as its argument. This method returns a sparse matrix that contains the hashed feature vectors for each row in the dataset.\n",
    "\n",
    "Finally, the toarray method of the sparse matrix object is called to convert it to a dense numpy array that can be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'color': 'red', 'fruit': 'apple'},\n",
       " {'color': 'blue', 'fruit': 'banana'},\n",
       " {'color': 'green', 'fruit': 'pear'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "data = [{'color': 'red', 'fruit': 'apple'},\n",
    "        {'color': 'blue', 'fruit': 'banana'},\n",
    "        {'color': 'green', 'fruit': 'pear'}]\n",
    "\n",
    "h = FeatureHasher(n_features=2, input_type='dict')\n",
    "f = h.transform(data)\n",
    "\n",
    "print(f.toarray())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [-1. -1.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "data = pd.DataFrame({'type': ['a', 'b', 'a', 'c', 'b'], 'model': ['bab', 'ba', 'ba', 'ce', 'bw']})\n",
    "\n",
    "h = FeatureHasher(n_features=2, input_type='string')\n",
    "f = h.transform(data.values.astype(str))\n",
    "\n",
    "print(f.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
